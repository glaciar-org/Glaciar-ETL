input {  

  file {
    type => "dataset_01_2009_2017_BO"
    
    # path => "${ELK_STACK_UELA_DATASET}/DATASET_01_2009_2017_BO.csv"
    path => "${ELK_STACK_UELA_DATASET}/DATASET_01_2009_2017_BO.small.borrar.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null" 
  }
  
}
filter {  

    # FECHA,HORA,AIRQ_CO,AIRQ_NO2,DATASET
    # 01/10/2009,14, , ,DATASET_01_2009_2017_BO
    # 01/10/2009,15,0.16,25,DATASET_01_2009_2017_BO
    # 01/10/2009,16,0.14,23,DATASET_01_2009_2017_BO
    # 01/10/2009,17,0.12,24,DATASET_01_2009_2017_BO

  csv {
      separator => ","
      columns => ["DATASET","FECHA","HORA","AIRQ_CO","AIRQ_NO2"]
  }
  

  mutate {
    add_field => { "fecha_time_stamp" => "%{FECHA} %{HORA}" }
  }

  date {

    #Â If you want to have "logtimestamp" become a time object,
    #    you need to add target => "logtimestamp" to your date filter block.
    # By default, the date filter overwrites the @timestamp field with the value of the matched field,
    #    in this case, logtimestamp's value. 
    # match => [ "FECHA", "dd/MM/yyyy" ]

    # match => [ "fecha_time_stamp", "dd/MM/yyyy HH:mm:ss" ]
    #    match => [ "HORA", "HH:mm:ss" ]
    # match => [ "fecha_time_stamp", "dd/MM/yyyy" ]
    match => [ "fecha_time_stamp", "dd/MM/yyyy HH" ]
    target => "FECHA_HORA"
    timezone => "Etc/GMT"
  }


  alter {
    condrewrite => [
         "AIRQ_CO", " ", "0",
         "AIRQ_NO", " ", "0",
         "AIRQ_NO2", " ", "0"
       ]
  }

 #mutate {convert => ["FECHA",  "float"]}
  mutate {convert => ["AIRQ_CO",  "float"]}
  mutate {convert => ["AIRQ_NO",  "float"]}
  mutate {convert => ["AIRQ_NO2",  "float"]}



# long              lat              	DIRECCION	            INICIO_DE_ACTIVIDAD	PARAMETROS_MEDIDOS	
# -58,3663735070165	-34,6252584813295	LA BOCA	AV. 01/05/2009  	CO, NO, NO2, NOX, PM10
# -58,4320717652753	-34,6066080998154	CENTENARIO	01/01/2005    CO, NO, NO2, NOX, PM10
# -58,391552893462	-34,5995643433432	CORDOBA	AV. 01/05/2009    CO, NO, NO2, NOX, PM10
# -58,4053598727298	-34,5834529467442	PALERMO	AV. 01/01/2002    CO, NO, NO2, NOX, PM10

  if [type] == "dataset_01_2009_2017_BO" {
      mutate {
        add_field => { "[location][lat]" => "-34.6252584813295" }
        add_field => { "[location][lon]" => "-58.3663735070165" }
      }
  } else if [type] == "dataset_01_2009_2017_CE" {
      mutate {
        add_field => { "[location][lat]" => "-34.6066080998154" }
        add_field => { "[location][lon]" => "-58.4320717652753" }
      }
  } else if [type] == "dataset_01_2009_2017_CO" {
      mutate {
        add_field => { "[location][lat]" => "-34.5995643433432" }
        add_field => { "[location][lon]" => "-58.391552893462"  }
      }
  } else if [type] == "dataset_01_2009_2017_PA" {
      mutate {
        add_field => { "[location][lat]" => "-34.5834529467442" }
        add_field => { "[location][lon]" => "-58.4053598727298" }
      }
  }
  mutate {
    convert => {"[location][lat]" => "float"}
    convert => {"[location][lon]" => "float"}
  }


}
output {  

    # elasticsearch {
    #     hosts => "http://localhost:9200"
    #     index => "uela-dataset-01-2010"
    # }

    elasticsearch {
        index    => "uela-dataset-01-small-bo9"
        hosts    => "${ELASTIC_xHOST}"
        user     => "${ELASTIC_xUSER}"
        password => "${ELASTIC_xPASS}"
    }   
  
  
    stdout {}

}
